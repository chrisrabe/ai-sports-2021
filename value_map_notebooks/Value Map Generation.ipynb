{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9edbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # pandas is not required in codebase (only useful for development/visusalisation)\n",
    "import matplotlib.pyplot as plt # visualisation\n",
    "import seaborn as sns # visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a9308",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eadff897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: in codebase, use get_world_dimension(world)\n",
    "# Setup value map\n",
    "def setup_value_map(world_dim=(9,9),\n",
    "                    pad_dim=(8,8),\n",
    "                    OUTER_MAP_VALUES=((-100, -100),(-100, -100))):\n",
    "    map_dim = np.add(world_dim,np.multiply(pad_dim,2))\n",
    "\n",
    "    # Initialise value map\n",
    "    world_map = np.zeros(world_dim)\n",
    "    value_map = np.pad(world_map, (pad_dim,pad_dim), 'constant', constant_values=OUTER_MAP_VALUES)\n",
    "    reward_value_map = value_map\n",
    "#     rval_offset = pad_dim[0]-1\n",
    "    rval_offset = pad_dim[0]\n",
    "    \n",
    "    # Initialise base map for reward mask matrix creation\n",
    "    base_map = np.zeros(map_dim)\n",
    "    \n",
    "    return reward_value_map, rval_offset\n",
    "    \n",
    "# Update value map based on reward entities input\n",
    "def update_value_map(rval, value_map, rval_offset, max_reward_spread=8):\n",
    "    reward = rval[2]\n",
    "    reward_discount = reward/abs(reward)\n",
    "    reward_spread=0\n",
    "    \n",
    "    # Max reward spread shall not exceed the dimension of the map\n",
    "    # (mask matrices of +1 or -1 are applied in additive layers that correspond to the magnitude of the reward value)\n",
    "    max_reward_spread = min(max_reward_spread, 9-1)\n",
    "    \n",
    "    if reward > 0:\n",
    "        # positive reward value\n",
    "        for i, value in enumerate(range(0, reward, 1)):\n",
    "            if i <= max_reward_spread:\n",
    "                reward_spread = i\n",
    "            xstart= rval[1] + rval_offset - reward_spread\n",
    "            xend = rval[1] + rval_offset + 1 + reward_spread\n",
    "            ystart = rval[0] + rval_offset - reward_spread\n",
    "            yend = rval[0] + rval_offset + 1 + reward_spread\n",
    "\n",
    "            value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "    elif reward < 0:\n",
    "        # negative reward value\n",
    "        for i, value in enumerate(range(0, reward, -1)):\n",
    "            if i <= max_reward_spread:\n",
    "                reward_spread = i \n",
    "            xstart= rval[1] + rval_offset - reward_spread\n",
    "            xend = rval[1] + rval_offset + 1 + reward_spread\n",
    "            ystart = rval[0] + rval_offset - reward_spread\n",
    "            yend = rval[0] + rval_offset + 1 + reward_spread\n",
    "\n",
    "            value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "    else:\n",
    "        # Reward assigned is 0.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583c877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a32bfc86",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d8641f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bomb': [5, 6, -6]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reward entities inputs (x, y, reward value)\n",
    "reward_entities = {\n",
    "    'bomb' : [5,6,-6],\n",
    "#     'ammo' : [2,2,6],\n",
    "#     'ammo' : [3,8,6],\n",
    "}\n",
    "\n",
    "reward_entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d33d17",
   "metadata": {},
   "source": [
    "## Updating the value map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf0db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Initialise value map\n",
    "reward_value_map, rval_offset = setup_value_map()\n",
    "\n",
    "# Updates value map based on reward entities input\n",
    "for rval in reward_entities.values():\n",
    "    update_value_map(rval, reward_value_map, rval_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093606d",
   "metadata": {},
   "source": [
    "## Visualising the value map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "177d9a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Value map visualisation\n",
    "df_map = pd.DataFrame(data=reward_value_map)\n",
    "df_map_visual = df_map.iloc[7:18,7:18]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax = sns.heatmap(reward_value_map[8:17,8:17], cmap='flare_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83d13271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       7      8      9      10     11     12     13     14     15     16  \\\n",
       "7  -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0 -100.0   \n",
       "8  -100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "9  -100.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   \n",
       "10 -100.0   -1.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   \n",
       "11 -100.0   -1.0   -2.0   -3.0   -3.0   -3.0   -3.0   -3.0   -3.0   -3.0   \n",
       "12 -100.0   -1.0   -2.0   -3.0   -4.0   -4.0   -4.0   -4.0   -4.0   -3.0   \n",
       "13 -100.0   -1.0   -2.0   -3.0   -4.0   -5.0   -5.0   -5.0   -4.0   -3.0   \n",
       "14 -100.0   -1.0   -2.0   -3.0   -4.0   -5.0   -6.0   -5.0   -4.0   -3.0   \n",
       "15 -100.0   -1.0   -2.0   -3.0   -4.0   -5.0   -5.0   -5.0   -4.0   -3.0   \n",
       "16 -100.0   -1.0   -2.0   -3.0   -4.0   -4.0   -4.0   -4.0   -4.0   -3.0   \n",
       "17 -100.0 -101.0 -102.0 -103.0 -103.0 -103.0 -103.0 -103.0 -103.0 -103.0   \n",
       "\n",
       "       17  \n",
       "7  -100.0  \n",
       "8  -100.0  \n",
       "9  -101.0  \n",
       "10 -102.0  \n",
       "11 -102.0  \n",
       "12 -102.0  \n",
       "13 -102.0  \n",
       "14 -102.0  \n",
       "15 -102.0  \n",
       "16 -102.0  \n",
       "17 -102.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdb97e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward = rval[2]\n",
    "# rdiscount = reward/abs(reward)\n",
    "# for i, value in enumerate(range(0, reward, -1)):\n",
    "#     xstart= rval[1] + rval_offset - i\n",
    "#     xend = rval[1] + rval_offset + 1 + i\n",
    "#     ystart = rval[0] + rval_offset - i\n",
    "#     yend = rval[0] + rval_offset + 1 + i\n",
    "    \n",
    "#     reward_value_map[xstart:xend,ystart:yend] = reward_value_map[xstart:xend,ystart:yend] + rdiscount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aef95568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update value map based on reward entities input\n",
    "# def update_value_map(rval, value_map, world_dim, OUTER_MAP_VALUES=((-100, -100),(-100, -100))):\n",
    "#     '''\n",
    "#     Updates the reward value map with mask matrix application, based on reward entity.\n",
    "#     Returns a numpy array representing the updated reward value map.\n",
    "#     '''\n",
    "#     # Add map padding\n",
    "#     pad_dim = (world_dim[0]-1,world_dim[1]-1)\n",
    "#     value_map = np.pad(value_map, (pad_dim,pad_dim), 'constant', constant_values=OUTER_MAP_VALUES)\n",
    "#     rval_offset = pad_dim[0]-1\n",
    "\n",
    "#     reward = rval[2]\n",
    "#     reward_discount = reward/abs(reward)\n",
    "#     rval_offset = 8 # padding offset\n",
    "    \n",
    "#     if reward > 0:\n",
    "#         # positive reward value\n",
    "#         for i, value in enumerate(range(0, reward, 1)):\n",
    "#             xstart= rval[1] + rval_offset - i\n",
    "#             xend = rval[1] + rval_offset + 1 + i\n",
    "#             ystart = rval[0] + rval_offset - i\n",
    "#             yend = rval[0] + rval_offset + 1 + i\n",
    "\n",
    "#             # Updates reward values in the map matrix.\n",
    "#             value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "#     elif reward < 0:\n",
    "#         # negative reward value\n",
    "#         for i, value in enumerate(range(0, reward, -1)):\n",
    "#             xstart= rval[1] + rval_offset - i\n",
    "#             xend = rval[1] + rval_offset + 1 + i\n",
    "#             ystart = rval[0] + rval_offset - i\n",
    "#             yend = rval[0] + rval_offset + 1 + i\n",
    "\n",
    "#             # Updates reward values in the map matrix.\n",
    "#             value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "#     else:\n",
    "#         # Reward assigned is 0.\n",
    "#         pass\n",
    "\n",
    "#     # Remove map padding\n",
    "#     value_map = value_map[world_dim[0]-1:world_dim[0]+pad_dim[0],world_dim[0]-1:world_dim[0]+pad_dim[0]]\n",
    "\n",
    "#     return value_map\n",
    "\n",
    "# def get_value_map(world, walls, game_objects, reward_map, pinch_points=None, use_default=True):\n",
    "#     \"\"\"\n",
    "#     Returns a numpy array map representing the values\n",
    "\n",
    "#     walls must be an array of (x,y) tuples\n",
    "\n",
    "#     game objects must be an array of objects with the following schema:\n",
    "#     {\n",
    "#        loc: (x, y)\n",
    "#        type: string\n",
    "#     }\n",
    "\n",
    "#     reward map must be a dictionary with the following schema\n",
    "#     {\n",
    "#        [ENTITY_TYPE]: number\n",
    "#     }\n",
    "\n",
    "#     pinch points must be an array of (x,y) tuples or is None (articulation points)\n",
    "\n",
    "#     use_default is a boolean to represent whether we should use the default reward map\n",
    "#     \"\"\"\n",
    "\n",
    "#     # TODO are there numpy helper functions to help with these logic?\n",
    "\n",
    "#     # create 2D matrix filled with zeroes\n",
    "#     value_map = np.zeros(get_world_dimension(world))\n",
    "\n",
    "#     # replace all walls with -10\n",
    "#     for wall in walls:\n",
    "#         x, y = wall\n",
    "#         value_map[y, x] = DEFAULT_REWARDS['wall']\n",
    "\n",
    "#     # get score mask for all non-wall objects\n",
    "#     for item in game_objects:\n",
    "#         if use_default:\n",
    "#             if item['type'] in reward_map:\n",
    "#                 reward = reward_map[item['type']]\n",
    "#             else:\n",
    "#                 reward = DEFAULT_REWARDS[item['type']]\n",
    "#         else:\n",
    "#             if item['type'] not in reward_map:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 reward = reward_map[item['type']]\n",
    "\n",
    "#         reward_entity = [item['loc'][0], item['loc'][1], reward]\n",
    "#         value_map = update_value_map(reward_entity, value_map)\n",
    "\n",
    "#     # re-evaluate for pinch points\n",
    "#     if pinch_points is not None:\n",
    "#         for tile in pinch_points:\n",
    "#             pinch_reward = DEFAULT_REWARDS['pinch']\n",
    "#             if 'pinch' in reward_map:\n",
    "#                 pinch_reward = reward_map['pinch']\n",
    "\n",
    "#             reward_entity = [tile['loc'][0], tile['loc'][1], pinch_reward]\n",
    "#             value_map = update_value_map(reward_entity, value_map)\n",
    "\n",
    "#     return value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c3020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
