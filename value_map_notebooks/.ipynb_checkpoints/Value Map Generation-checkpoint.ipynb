{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9edbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # pandas is not required in codebase (only useful for development/visusalisation)\n",
    "import matplotlib.pyplot as plt # visualisation\n",
    "import seaborn as sns # visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a9308",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadff897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: in codebase, use get_world_dimension(world)\n",
    "# Setup value map\n",
    "def setup_value_map(world_dim=(9,9),\n",
    "                    pad_dim=(8,8),\n",
    "                    OUTER_MAP_VALUES=((-100, -100),(-100, -100))):\n",
    "    map_dim = np.add(world_dim,np.multiply(pad_dim,2))\n",
    "\n",
    "    # Initialise value map\n",
    "    world_map = np.zeros(world_dim)\n",
    "    value_map = np.pad(world_map, (pad_dim,pad_dim), 'constant', constant_values=OUTER_MAP_VALUES)\n",
    "    reward_value_map = value_map\n",
    "    rval_offset = pad_dim[0]\n",
    "\n",
    "    # Initialise base map for reward mask matrix creation\n",
    "    base_map = np.zeros(map_dim)\n",
    "    \n",
    "    return reward_value_map, rval_offset\n",
    "    \n",
    "# Update value map based on reward entities input\n",
    "def update_value_map(rval, value_map, rval_offset, max_reward_spread=3):\n",
    "    reward = rval[2]\n",
    "    reward_discount = reward/abs(reward)\n",
    "    reward_spread=0\n",
    "    \n",
    "    # Max reward spread shall be no greater than the dimension of the map\n",
    "    # (mask matrices of +1 or -1 are applied in additive layers that correspond to the magnitude of the reward value)\n",
    "    max_reward_spread = min(max_reward_spread, 9-1)\n",
    "    \n",
    "    if reward > 0:\n",
    "        # positive reward value\n",
    "        for i, value in enumerate(range(0, reward, 1)):\n",
    "            if i <= max_reward_spread:\n",
    "                reward_spread = i\n",
    "            xstart= rval[1] + rval_offset - reward_spread\n",
    "            xend = rval[1] + rval_offset + 1 + reward_spread\n",
    "            ystart = rval[0] + rval_offset - reward_spread\n",
    "            yend = rval[0] + rval_offset + 1 + reward_spread\n",
    "\n",
    "            value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "    elif reward < 0:\n",
    "        # negative reward value\n",
    "        for i, value in enumerate(range(0, reward, -1)):\n",
    "            if i <= max_reward_spread:\n",
    "                reward_spread = i \n",
    "            xstart= rval[1] + rval_offset - reward_spread\n",
    "            xend = rval[1] + rval_offset + 1 + reward_spread\n",
    "            ystart = rval[0] + rval_offset - reward_spread\n",
    "            yend = rval[0] + rval_offset + 1 + reward_spread\n",
    "\n",
    "            value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "    else:\n",
    "        # Reward assigned is 0.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189baeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a32bfc86",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8641f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bomb': [5, 6, -6]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reward entities inputs (x, y, reward value)\n",
    "reward_entities = {\n",
    "    'bomb' : [5,6,-6],\n",
    "#     'ammo' : [2,2,6],\n",
    "#     'ammo' : [3,8,6],\n",
    "}\n",
    "\n",
    "reward_entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d33d17",
   "metadata": {},
   "source": [
    "## Updating the value map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf0db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise value map\n",
    "reward_value_map, rval_offset = setup_value_map()\n",
    "\n",
    "# Updates value map based on reward entities input\n",
    "for rval in reward_entities.values():\n",
    "    update_value_map(rval, reward_value_map, rval_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093606d",
   "metadata": {},
   "source": [
    "## Visualising the value map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d9a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Value map visualisation\n",
    "df_map = pd.DataFrame(data=reward_value_map)\n",
    "df_map_visual = df_map.iloc[7:18,7:18]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax = sns.heatmap(reward_value_map[8:17,8:17], cmap='flare_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cdb97e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward = rval[2]\n",
    "# rdiscount = reward/abs(reward)\n",
    "# for i, value in enumerate(range(0, reward, -1)):\n",
    "#     xstart= rval[1] + rval_offset - i\n",
    "#     xend = rval[1] + rval_offset + 1 + i\n",
    "#     ystart = rval[0] + rval_offset - i\n",
    "#     yend = rval[0] + rval_offset + 1 + i\n",
    "    \n",
    "#     reward_value_map[xstart:xend,ystart:yend] = reward_value_map[xstart:xend,ystart:yend] + rdiscount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aef95568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update value map based on reward entities input\n",
    "# def update_value_map(rval, value_map, world_dim, OUTER_MAP_VALUES=((-100, -100),(-100, -100))):\n",
    "#     '''\n",
    "#     Updates the reward value map with mask matrix application, based on reward entity.\n",
    "#     Returns a numpy array representing the updated reward value map.\n",
    "#     '''\n",
    "#     # Add map padding\n",
    "#     pad_dim = (world_dim[0]-1,world_dim[1]-1)\n",
    "#     value_map = np.pad(value_map, (pad_dim,pad_dim), 'constant', constant_values=OUTER_MAP_VALUES)\n",
    "#     rval_offset = pad_dim[0]-1\n",
    "\n",
    "#     reward = rval[2]\n",
    "#     reward_discount = reward/abs(reward)\n",
    "#     rval_offset = 8 # padding offset\n",
    "    \n",
    "#     if reward > 0:\n",
    "#         # positive reward value\n",
    "#         for i, value in enumerate(range(0, reward, 1)):\n",
    "#             xstart= rval[1] + rval_offset - i\n",
    "#             xend = rval[1] + rval_offset + 1 + i\n",
    "#             ystart = rval[0] + rval_offset - i\n",
    "#             yend = rval[0] + rval_offset + 1 + i\n",
    "\n",
    "#             # Updates reward values in the map matrix.\n",
    "#             value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "            \n",
    "#     elif reward < 0:\n",
    "#         # negative reward value\n",
    "#         for i, value in enumerate(range(0, reward, -1)):\n",
    "#             xstart= rval[1] + rval_offset - i\n",
    "#             xend = rval[1] + rval_offset + 1 + i\n",
    "#             ystart = rval[0] + rval_offset - i\n",
    "#             yend = rval[0] + rval_offset + 1 + i\n",
    "\n",
    "#             # Updates reward values in the map matrix.\n",
    "#             value_map[xstart:xend,ystart:yend] = value_map[xstart:xend,ystart:yend] + reward_discount\n",
    "#     else:\n",
    "#         # Reward assigned is 0.\n",
    "#         pass\n",
    "\n",
    "#     # Remove map padding\n",
    "#     value_map = value_map[world_dim[0]-1:world_dim[0]+pad_dim[0],world_dim[0]-1:world_dim[0]+pad_dim[0]]\n",
    "\n",
    "#     return value_map\n",
    "\n",
    "# def get_value_map(world, walls, game_objects, reward_map, pinch_points=None, use_default=True):\n",
    "#     \"\"\"\n",
    "#     Returns a numpy array map representing the values\n",
    "\n",
    "#     walls must be an array of (x,y) tuples\n",
    "\n",
    "#     game objects must be an array of objects with the following schema:\n",
    "#     {\n",
    "#        loc: (x, y)\n",
    "#        type: string\n",
    "#     }\n",
    "\n",
    "#     reward map must be a dictionary with the following schema\n",
    "#     {\n",
    "#        [ENTITY_TYPE]: number\n",
    "#     }\n",
    "\n",
    "#     pinch points must be an array of (x,y) tuples or is None (articulation points)\n",
    "\n",
    "#     use_default is a boolean to represent whether we should use the default reward map\n",
    "#     \"\"\"\n",
    "\n",
    "#     # TODO are there numpy helper functions to help with these logic?\n",
    "\n",
    "#     # create 2D matrix filled with zeroes\n",
    "#     value_map = np.zeros(get_world_dimension(world))\n",
    "\n",
    "#     # replace all walls with -10\n",
    "#     for wall in walls:\n",
    "#         x, y = wall\n",
    "#         value_map[y, x] = DEFAULT_REWARDS['wall']\n",
    "\n",
    "#     # get score mask for all non-wall objects\n",
    "#     for item in game_objects:\n",
    "#         if use_default:\n",
    "#             if item['type'] in reward_map:\n",
    "#                 reward = reward_map[item['type']]\n",
    "#             else:\n",
    "#                 reward = DEFAULT_REWARDS[item['type']]\n",
    "#         else:\n",
    "#             if item['type'] not in reward_map:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 reward = reward_map[item['type']]\n",
    "\n",
    "#         reward_entity = [item['loc'][0], item['loc'][1], reward]\n",
    "#         value_map = update_value_map(reward_entity, value_map)\n",
    "\n",
    "#     # re-evaluate for pinch points\n",
    "#     if pinch_points is not None:\n",
    "#         for tile in pinch_points:\n",
    "#             pinch_reward = DEFAULT_REWARDS['pinch']\n",
    "#             if 'pinch' in reward_map:\n",
    "#                 pinch_reward = reward_map['pinch']\n",
    "\n",
    "#             reward_entity = [tile['loc'][0], tile['loc'][1], pinch_reward]\n",
    "#             value_map = update_value_map(reward_entity, value_map)\n",
    "\n",
    "#     return value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7222c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
